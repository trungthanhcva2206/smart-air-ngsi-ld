"""
/*
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 * @Project smart-air-ngsi-ld
 * @Authors 
 *    - TT (trungthanhcva2206@gmail.com)
 *    - Tankchoi (tadzltv22082004@gmail.com)
 *    - Panh (panh812004.apn@gmail.com)
 * @Copyright (C) 2025 CHK. All rights reserved
 * @GitHub https://github.com/trungthanhcva2206/smart-air-ngsi-ld
 */
"""
import os
import logging
import geopandas as gpd
import networkx as nx
import osmnx as ox
import numpy as np
import pandas as pd
from flask import Flask, jsonify, request
from flask_cors import CORS
from shapely.geometry import LineString
import warnings
import math
import unicodedata
import re
import threading
import time
import requests
import sseclient
import json
from dotenv import load_dotenv

# Load environment variables from .env file
load_dotenv()

warnings.filterwarnings("ignore", category=UserWarning, module="osmnx")
warnings.filterwarnings("ignore", category=FutureWarning)

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

app = Flask(__name__)
CORS(app)

# Load configuration from environment variables
GRAPH_FILE = os.getenv("GRAPH_FILE", "hanoi_road_network.graphml")
GEOJSON_FILE = os.getenv("GEOJSON_FILE", "ha_noi_with_latlon2.geojson")
SSE_ENDPOINT = os.getenv("SSE_ENDPOINT", "http://localhost:8123/api/sse/environment-data")
FLASK_HOST = os.getenv("FLASK_HOST", "127.0.0.1")
FLASK_PORT = int(os.getenv("FLASK_PORT", "5000"))
FLASK_DEBUG = os.getenv("FLASK_DEBUG", "False").lower() == "true"

G_base = None
G_main = None
zones_gdf = None
mock_env_data = {}
data_lock = threading.Lock()

# Bi·∫øn to√†n c·ª•c cho Edges GDF (ƒë·ªÉ tƒÉng t·ªëc)
edges_gdf_main = None

def normalize_zone_name(zone_name):
    """
    Normalize zone name to match Spring Boot format
    Example: "Ph∆∞·ªùng Ho√†n Ki·∫øm" -> "PhuongHoanKiem"
    """
    if not zone_name:
        return zone_name
    
    text = zone_name.replace('ƒê', 'D').replace('ƒë', 'd')
    nfd = unicodedata.normalize('NFD', text)
    without_accents = nfd.encode('ascii', 'ignore').decode('utf-8')
    without_accents = re.sub(r'[^\w\s]', ' ', without_accents)
    words = without_accents.split()
    pascal_case = ''.join(word.capitalize() for word in words)
    
    logger.debug(f"normalize_zone_name: '{zone_name}' -> '{pascal_case}'")
    return pascal_case

def sse_listener():
    """
    Listen to SSE stream from Spring Boot Backend
    Updates mock_env_data and G_main when new data arrives
    Auto-reconnects on connection loss
    """
    global G_main, G_base, zones_gdf, data_lock, edges_gdf_main, mock_env_data
    
    logger.info(f"[SSE Listener] üîå ƒêang k·∫øt n·ªëi t·ªõi SSE endpoint: {SSE_ENDPOINT}")
    
    while True:
        try:
            response = requests.get(SSE_ENDPOINT, stream=True, timeout=None)
            client = sseclient.SSEClient(response)
            
            logger.info("[SSE Listener] ‚úÖ K·∫øt n·ªëi SSE th√†nh c√¥ng!")
            
            for event in client.events():
                try:
                    if event.event == "environment.initial":
                        logger.info("[SSE Listener] üì¶ Nh·∫≠n d·ªØ li·ªáu ban ƒë·∫ßu t·ª´ Backend...")
                        handle_environment_data(json.loads(event.data))
                    
                    elif event.event == "environment.update":
                        logger.info("[SSE Listener] üîÑ Nh·∫≠n c·∫≠p nh·∫≠t d·ªØ li·ªáu m√¥i tr∆∞·ªùng...")
                        handle_environment_data(json.loads(event.data))
                    
                    elif event.event == "keep-alive":
                        logger.debug("[SSE Listener] ‚ù§Ô∏è Keep-alive received")
                        
                except json.JSONDecodeError as e:
                    logger.error(f"[SSE Listener] L·ªói parse JSON: {e}")
                except Exception as e:
                    logger.error(f"[SSE Listener] L·ªói x·ª≠ l√Ω event: {e}")
        
        except requests.exceptions.RequestException as e:
            logger.error(f"[SSE Listener] ‚ùå L·ªói k·∫øt n·ªëi SSE: {e}")
            logger.info("[SSE Listener] üîÑ ƒêang th·ª≠ k·∫øt n·ªëi l·∫°i sau 5 gi√¢y...")
            time.sleep(5)
        except Exception as e:
            logger.error(f"[SSE Listener] ‚ùå L·ªói kh√¥ng x√°c ƒë·ªãnh: {e}")
            time.sleep(5)

def handle_environment_data(spring_data):
    """
    Process environment data from SSE stream
    Updates mock_env_data and recalculates graph costs
    
    Args:
        spring_data: Dict with format {stationName: AirQualityDataDTO}
    """
    global G_main, G_base, zones_gdf, data_lock, edges_gdf_main, mock_env_data
    
    try:
        if not spring_data:
            logger.warning("[SSE Handler] Nh·∫≠n d·ªØ li·ªáu r·ªóng, b·ªè qua.")
            return
        
        logger.info(f"[SSE Handler] üîÑ ƒêang x·ª≠ l√Ω {len(spring_data)} ƒëi·ªÉm d·ªØ li·ªáu...")
        
        zone_names = zones_gdf["T√™n ƒë∆°n v·ªã"].tolist()
        zone_name_mapping = {zone: normalize_zone_name(zone) for zone in zone_names}
        reverse_mapping = {v: k for k, v in zone_name_mapping.items()}

        station_to_zone = {
        }
        
        all_data = {}
        for spring_key, data in spring_data.items():
            all_data = {}
        for spring_key, data in spring_data.items():
            # ∆Øu ti√™n mapping t·ª´ station_to_zone
            original_name = station_to_zone.get(spring_key)
            if not original_name:
                original_name = reverse_mapping.get(spring_key)

            if original_name:
                all_data[original_name] = {
                    "NO": data.get('no', 0),
                    "O3": data.get('o3', 0),
                    "NO2": data.get('no2', 0),
                    "NOx": data.get('nox', 0),
                    "SO2": data.get('so2', 0),
                    "pm2_5": data.get('pm2_5', 0),
                    "pm10": data.get('pm10', 0),
                    "nh3": data.get('nh3', 0),
                    "windSpeed": data.get('windSpeed', 0),
                }
                logger.debug(f"‚úì Mapped: '{spring_key}' -> '{original_name}'")
        
        if not all_data:
            logger.warning("[SSE Handler] Kh√¥ng map ƒë∆∞·ª£c d·ªØ li·ªáu n√†o!")
            return
        
        # Create DataFrame from new data
        df = pd.DataFrame.from_dict(all_data, orient='index')
        df = df.reindex(zone_names)
        mean_vals = df.mean()
        df = df.fillna(mean_vals)
        df.loc["_mean_"] = mean_vals
        
        # Update mock_env_data
        with data_lock:
            mock_env_data = df.to_dict(orient='index')
            logger.info("[SSE Handler] ‚úÖ ƒê√£ c·∫≠p nh·∫≠t mock_env_data")
        
        # Recalculate graph costs
        logger.info("[SSE Handler] üîÑ ƒêang t√≠nh to√°n l·∫°i chi ph√≠ cho ƒë·ªì th·ªã...")
        G_main_new = precalculate_all_costs(G_base.copy(), zones_gdf, df)
        
        with data_lock:
            G_main = G_main_new
            edges_gdf_main = ox.graph_to_gdfs(G_main, nodes=False, edges=True)
            logger.info("[SSE Handler] ‚úÖ ƒê√£ c·∫≠p nh·∫≠t G_main v√† edges_gdf_main!")
            
    except Exception as e:
        logger.error(f"[SSE Handler] ‚ùå L·ªói x·ª≠ l√Ω d·ªØ li·ªáu: {e}")

def precalculate_all_costs(road_graph, zones_gdf, env_df):
    """
    Precalculate routing costs for all edges based on environmental data
    Uses vectorized operations for performance
    """
    logger.info("ƒêang vector h√≥a GDFs (nodes/edges)...")
    nodes_gdf = ox.graph_to_gdfs(road_graph, edges=False)
    edges_gdf = ox.graph_to_gdfs(road_graph, nodes=False)
    mean_vals = env_df.loc["_mean_"]
    zones_with_env = zones_gdf.merge(env_df, left_on="T√™n ƒë∆°n v·ªã", right_index=True, how="left").fillna(mean_vals)
    
    logger.info("ƒêang th·ª±c hi·ªán Spatial Join (nodes v√†o zones)...")
    nodes_in_zones = gpd.sjoin(nodes_gdf, zones_with_env, how="left", predicate="within")
    
    env_columns = ["NO", "O3", "NO2", "NOx", "SO2", "pm2_5", "pm10", "nh3", "windSpeed"]
    nodes_in_zones[env_columns] = nodes_in_zones[env_columns].fillna(mean_vals)
    node_env_data = nodes_in_zones[env_columns]
    
    logger.info("ƒêang merge chi ph√≠ v√†o c√°c c·∫°nh (edges)...")
    edges_with_data = edges_gdf.merge(node_env_data, left_on='u', right_index=True, how='left')
    edges_with_data = edges_with_data.merge(node_env_data, left_on='v', right_index=True, how='left', suffixes=('_u', '_v'))
    edges_with_data = edges_with_data.fillna(mean_vals)
    
    logger.info("ƒêang t√≠nh to√°n chi ph√≠ (vectorized)...")
    
    avg_no = (edges_with_data['NO_u'] + edges_with_data['NO_v']) / 2
    avg_o3 = (edges_with_data['O3_u'] + edges_with_data['O3_v']) / 2
    avg_no2 = (edges_with_data['NO2_u'] + edges_with_data['NO2_v']) / 2
    avg_nox = (edges_with_data['NOx_u'] + edges_with_data['NOx_v']) / 2
    avg_so2 = (edges_with_data['SO2_u'] + edges_with_data['SO2_v']) / 2
    avg_pm25 = (edges_with_data['pm2_5_u'] + edges_with_data['pm2_5_v']) / 2
    avg_pm10 = (edges_with_data['pm10_u'] + edges_with_data['pm10_v']) / 2
    avg_nh3 = (edges_with_data['nh3_u'] + edges_with_data['nh3_v']) / 2
    avg_windspeed = (edges_with_data['windSpeed_u'] + edges_with_data['windSpeed_v']) / 2
    
    length = edges_with_data['length']
    
    # Cost for clean air route (higher weight on pollutants)
    # Wind speed c√†ng cao ‚Üí gi·∫£m chi ph√≠ (gi√≥ m·∫°nh th·ªïi bay √¥ nhi·ªÖm)
    cost_wind = (length + 
                 avg_no * 10 + avg_o3 * 8 + avg_no2 * 12 + 
                 avg_nox * 9 + avg_so2 * 7 + avg_pm25 * 15 +
                 avg_pm10 * 12 + avg_nh3 * 8 - avg_windspeed * 5)
    
    # Cost for shortest route (lower weight on pollutants)
    cost_short = (length * 1.5 + 
                  avg_no * 6 + avg_o3 * 5 + avg_no2 * 8 + 
                  avg_nox * 5 + avg_so2 * 4 + avg_pm25 * 10 +
                  avg_pm10 * 7 + avg_nh3 * 5 - avg_windspeed * 3)
    
    logger.info("ƒêang g√°n thu·ªôc t√≠nh chi ph√≠ v√†o ƒë·ªì th·ªã...")
    nx.set_edge_attributes(road_graph, cost_wind.to_dict(), 'cost_wind')
    nx.set_edge_attributes(road_graph, cost_short.to_dict(), 'cost_short')
       # --- G√ÅN THU·ªòC T√çNH POLLUTANTS V√Ä C√ÅC TR∆Ø·ªúNG TI·ªÜN √çCH (ƒë·ªÉ edges_gdf c√≥ d·ªØ li·ªáu) ---
    try:
        # trung b√¨nh 2 ƒë·∫ßu (ƒë√£ t√≠nh ·ªü tr√™n)
        nx.set_edge_attributes(road_graph, avg_pm25.to_dict(), 'pm2_5')
        nx.set_edge_attributes(road_graph, avg_pm10.to_dict(), 'pm10')
        nx.set_edge_attributes(road_graph, avg_windspeed.to_dict(), 'windSpeed')

        # gi·ªØ c·∫£ gi√° tr·ªã ·ªü hai ƒë·∫ßu n·∫øu c·∫ßn (u/v)
        nx.set_edge_attributes(road_graph, edges_with_data['pm2_5_u'].to_dict(), 'pm2_5_u')
        nx.set_edge_attributes(road_graph, edges_with_data['pm2_5_v'].to_dict(), 'pm2_5_v')
        nx.set_edge_attributes(road_graph, edges_with_data['pm10_u'].to_dict(), 'pm10_u')
        nx.set_edge_attributes(road_graph, edges_with_data['pm10_v'].to_dict(), 'pm10_v')
    except Exception as e:
        logger.warning(f"Kh√¥ng th·ªÉ g√°n thu·ªôc t√≠nh pollutants l√™n graph: {e}")
    logger.info("‚úÖ T√≠nh to√°n tr∆∞·ªõc chi ph√≠ th√†nh c√¥ng!")
    return road_graph

def find_route_classical(graph, start_node, end_node, weight_attr):
    """
    Find shortest path using Dijkstra's algorithm
    """
    logger.info(f"ƒêang t√¨m ƒë∆∞·ªùng ƒëi c·ªï ƒëi·ªÉn (weight={weight_attr})...")
    try:
        path = nx.shortest_path(graph, start_node, end_node, weight=weight_attr)
        return path
    except nx.NetworkXNoPath:
        logger.error("Kh√¥ng t√¨m th·∫•y ƒë∆∞·ªùng ƒëi.")
        return None

def load_all_data():
    """
    Load initial data: road network, zones
    Then start SSE listener thread for real-time updates
    SSE will provide initial environment data via "environment.initial" event
    """
    global G_main, G_base, zones_gdf, edges_gdf_main, mock_env_data
    
    if not os.path.exists(GRAPH_FILE):
        logger.error(f"Kh√¥ng t√¨m th·∫•y t·ªáp {GRAPH_FILE}")
        exit()

    logger.info(f"ƒêang t·∫£i b·∫£n ƒë·ªì ƒë∆∞·ªùng ƒëi t·ª´ {GRAPH_FILE}...")
    G_base = ox.load_graphml(GRAPH_FILE)
    
    logger.info(f"ƒêang t·∫£i b·∫£n ƒë·ªì v√πng t·ª´ {GEOJSON_FILE}...")
    zones_gdf = gpd.read_file(GEOJSON_FILE)
    zones_gdf = zones_gdf.to_crs(G_base.graph["crs"])
    zone_names = zones_gdf["T√™n ƒë∆°n v·ªã"].tolist()
    
    logger.info(f"T√¨m th·∫•y {len(zone_names)} zones trong GeoJSON")

    # Kh·ªüi t·∫°o v·ªõi d·ªØ li·ªáu m·∫∑c ƒë·ªãnh
    logger.info("Kh·ªüi t·∫°o ƒë·ªì th·ªã v·ªõi d·ªØ li·ªáu m√¥i tr∆∞·ªùng m·∫∑c ƒë·ªãnh...")
    default_data = {zone: {
        "NO": 0.0, "O3": 0.0, "NO2": 0.0,
        "NOx": 0.0, "SO2": 0.0, "pm2_5": 0.0,"pm10": 0.0,
        "nh3": 0.0,
        "windSpeed": 0.0,
    } for zone in zone_names}
    env_df_initial = pd.DataFrame.from_dict(default_data, orient='index')
    mean_vals = env_df_initial.mean()
    env_df_initial.loc["_mean_"] = mean_vals
    
    with data_lock:
        mock_env_data = env_df_initial.to_dict(orient='index')
        G_main = precalculate_all_costs(G_base.copy(), zones_gdf, env_df_initial)
        edges_gdf_main = ox.graph_to_gdfs(G_main, nodes=False, edges=True)
        
    logger.info("‚úÖ ƒê·ªì th·ªã ƒë√£ ƒë∆∞·ª£c kh·ªüi t·∫°o v·ªõi gi√° tr·ªã m·∫∑c ƒë·ªãnh")
    logger.info("‚è≥ Ch·ªù d·ªØ li·ªáu th·ª±c t·ª´ SSE stream...")

    # Kh·ªüi ƒë·ªông SSE listener
    logger.info("üîå Kh·ªüi ƒë·ªông SSE listener ƒë·ªÉ nh·∫≠n real-time updates...")
    sse_thread = threading.Thread(target=sse_listener)
    sse_thread.daemon = True
    sse_thread.start()
    
    logger.info("‚úÖ H·ªá th·ªëng ƒë√£ s·∫µn s√†ng!")

@app.route("/api/get-env", methods=["GET"])
def get_env_data():
    """
    Tr·∫£ v·ªÅ d·ªØ li·ªáu m√¥i tr∆∞·ªùng m·ªõi nh·∫•t cho t·ª´ng ph∆∞·ªùng/x√£
    D·ªØ li·ªáu n√†y ƒë√£ ƒë∆∞·ª£c c·∫≠p nh·∫≠t t·ª´ SSE Spring Boot (bao g·ªìm c·∫£ thi·∫øt b·ªã th·∫≠t)
    """
    global mock_env_data, data_lock

    with data_lock:
        # Tr·∫£ v·ªÅ d·ªØ li·ªáu m·ªõi nh·∫•t cho t·ª´ng zone (ph∆∞·ªùng/x√£)
        # Format: {zone_name: {NO, O3, NO2, NOx, SO2, pm2_5, pm10, nh3, windSpeed}}
        return jsonify(mock_env_data)

@app.route("/api/find-route", methods=["POST"])
def find_route_api():
    """
    Find optimal route between two points
    Supports two modes: 'wind' (clean air) and 'short' (shortest)
    """
    global G_main, data_lock, edges_gdf_main
    
    data = request.json
    start_coords = data.get("start")
    end_coords = data.get("end")
    mode = data.get("mode", "wind")

    if not start_coords or not end_coords:
        return jsonify({"error": "Thi·∫øu t·ªça ƒë·ªô b·∫Øt ƒë·∫ßu ho·∫∑c k·∫øt th√∫c"}), 400

    if mode == "wind":
        weight_attr = "cost_wind"
        logger.info("S·ª≠ d·ª•ng 'cost_wind' l√†m tr·ªçng s·ªë.")
    else:
        weight_attr = "cost_short"
        logger.info("S·ª≠ d·ª•ng 'cost_short' l√†m tr·ªçng s·ªë.")
    
    with data_lock:
        if G_main is None or edges_gdf_main is None:
             return jsonify({"error": "ƒê·ªì th·ªã ch∆∞a ƒë∆∞·ª£c t·∫£i, vui l√≤ng kh·ªüi ƒë·ªông l·∫°i server."}), 500
        G_current = G_main
        edges_gdf = edges_gdf_main
    
    try:
        start_node = ox.nearest_nodes(G_current, *start_coords)
        end_node = ox.nearest_nodes(G_current, *end_coords)
        path_nodes = find_route_classical(G_current, start_node, end_node, weight_attr)
    except Exception as e:
        logger.error(f"L·ªói trong qu√° tr√¨nh t√¨m ƒë∆∞·ªùng: {e}")
        return jsonify({"error": "L·ªói m√°y ch·ªß khi t√¨m ƒë∆∞·ªùng."}), 500
    
    if path_nodes is None:
        return jsonify({"error": "Kh√¥ng t√¨m th·∫•y ƒë∆∞·ªùng ƒëi"}), 404

    edge_tuples = list(zip(path_nodes[:-1], path_nodes[1:]))
    route_edges_gdf = edges_gdf.loc[edges_gdf.index.map(lambda idx: (idx[0], idx[1]) in edge_tuples)]
    route_geojson_gdf = route_edges_gdf.to_crs(epsg=4326)
    route_geojson = route_geojson_gdf.__geo_interface__

    # ===== LOGIC CH·ªà ƒê∆Ø·ªúNG M·ªöI (CH√çNH X√ÅC H∆†N) v2.0 =====
    def bearing(p1, p2):
        lon1, lat1, lon2, lat2 = map(math.radians, [p1[0], p1[1], p2[0], p2[1]])
        dlon = lon2 - lon1
        x = math.sin(dlon) * math.cos(lat2)
        y = math.cos(lat1)*math.sin(lat2) - math.sin(lat1)*math.cos(lat2)*math.cos(dlon)
        return (math.degrees(math.atan2(x, y)) + 360) % 360

    def turn_direction(b1, b2):
        delta = (b2 - b1 + 540) % 360 - 180
        if abs(delta) < 30:
            return "ƒëi th·∫≥ng"
        elif delta > 0:
            return "r·∫Ω ph·∫£i"
        else:
            return "r·∫Ω tr√°i"

    directions_text = []
    
    if route_edges_gdf.empty:
        return jsonify({
            "route_geojson": route_geojson,
            "directions": ["Kh√¥ng th·ªÉ t·∫°o l·ªô tr√¨nh chi ti·∫øt."],
            "mode": mode
        })

    current_road = None
    current_distance = 0
    prev_end_bearing = None

    for i, (_, edge) in enumerate(route_edges_gdf.iterrows()):
        geom = edge.geometry
        if geom.geom_type != "LineString":
            continue

        coords = list(geom.coords)
        if len(coords) < 2:
            continue

        start_bearing = bearing(coords[0], coords[1])
        end_bearing = bearing(coords[-2], coords[-1])

        road_name = edge.get("name")
        if isinstance(road_name, list):
            road_name = road_name[0] if road_name else "ƒê∆∞·ªùng kh√¥ng t√™n"
        elif not isinstance(road_name, str) or pd.isna(road_name):
            road_name = "ƒê∆∞·ªùng kh√¥ng t√™n"
        
        dist_m = edge.get("length", 0)

        if i == 0:
            current_road = road_name
            current_distance = dist_m
            directions_text.append(f"Xu·∫•t ph√°t tr√™n {current_road}")
        else:
            turn = turn_direction(prev_end_bearing, start_bearing) 
            
            if road_name == current_road and turn == "ƒëi th·∫≥ng":
                current_distance += dist_m
            else: 
                if current_distance > 0 and directions_text:
                    last_instruction = directions_text.pop()
                    directions_text.append(f"{last_instruction} (kho·∫£ng {int(current_distance)} m).")
                
                if road_name == current_road: 
                    directions_text.append(f"{turn.capitalize()} ƒë·ªÉ ti·∫øp t·ª•c tr√™n {road_name}")
                else: 
                    directions_text.append(f"{turn.capitalize()} v√†o {road_name}")
                
                current_road = road_name
                current_distance = dist_m

        prev_end_bearing = end_bearing 

    if current_distance > 0 and directions_text:
        last_instruction = directions_text.pop()
        directions_text.append(f"{last_instruction} (kho·∫£ng {int(current_distance)} m).")

    directions_text.append("ƒê·∫øn ƒëi·ªÉm ƒë√≠ch.")
    # ===== K·∫æT TH√öC LOGIC CH·ªà ƒê∆Ø·ªúNG v2.0 =====
    
    return jsonify({
        "route_geojson": route_geojson,
        "directions": directions_text,
        "mode": mode
    })

@app.route("/api/find-both-routes", methods=["POST"])
def find_both_routes():
    global G_main, data_lock, edges_gdf_main

    data = request.json
    start_coords = data.get("start")
    end_coords = data.get("end")

    if not start_coords or not end_coords:
        return jsonify({"error": "Thi·∫øu t·ªça ƒë·ªô"}), 400

    with data_lock:
        G = G_main
        edges_gdf = edges_gdf_main

    try:
        start_node = ox.nearest_nodes(G, *start_coords)
        end_node = ox.nearest_nodes(G, *end_coords)

        # T√¨m 2 tuy·∫øn
        path_wind = find_route_classical(G, start_node, end_node, "cost_wind")
        path_short = find_route_classical(G, start_node, end_node, "cost_short")

        def build_route(path_nodes):
            edge_pairs = list(zip(path_nodes[:-1], path_nodes[1:]))
            r_edges = edges_gdf.loc[
                edges_gdf.index.map(lambda idx: (idx[0], idx[1]) in edge_pairs)
            ]
            geo = r_edges.to_crs(epsg=4326).__geo_interface__

            total_dist = r_edges["length"].sum()
            if "pm2_5" in r_edges.columns:
                avg_pm25 = float(r_edges["pm2_5"].mean() or 0.0)
            elif all(c in r_edges.columns for c in ["pm2_5_u", "pm2_5_v"]):
                avg_pm25 = float(r_edges[["pm2_5_u", "pm2_5_v"]].mean(axis=1).mean() or 0.0)
            else:
                avg_pm25 = 0.0
            time_min = total_dist / 1000 / 30 * 60   # v·∫≠n t·ªëc 30km/h

            return {
                "geojson": geo,
                "distance_m": float(total_dist),
                "time_min": float(time_min),
                "pm25_avg": float(avg_pm25),
            }

        result_wind = build_route(path_wind)
        result_short = build_route(path_short)

        return jsonify({
            "wind": result_wind,
            "short": result_short,
        })

    except Exception as e:
        logger.error(f"L·ªói: {e}")
        return jsonify({"error": "L·ªói x·ª≠ l√Ω"}), 500

@app.route("/health", methods=["GET"])
def health_check():
    """
    Health check endpoint for Docker and load balancers
    Returns service status and graph availability
    """
    global G_main, zones_gdf, mock_env_data
    
    try:
        # Check if graph is loaded
        graph_loaded = G_main is not None and zones_gdf is not None
        
        # Check if environment data is available
        env_data_available = len(mock_env_data) > 0
        
        # Get data stats
        num_zones = len(zones_gdf) if zones_gdf is not None else 0
        num_nodes = G_main.number_of_nodes() if G_main is not None else 0
        num_edges = G_main.number_of_edges() if G_main is not None else 0
        
        status = {
            "status": "healthy" if graph_loaded else "initializing",
            "service": "route-finding",
            "graph_loaded": graph_loaded,
            "env_data_available": env_data_available,
            "stats": {
                "zones": num_zones,
                "nodes": num_nodes,
                "edges": num_edges,
                "env_data_points": len(mock_env_data)
            }
        }
        
        return jsonify(status), 200 if graph_loaded else 503
        
    except Exception as e:
        logger.error(f"Health check failed: {e}")
        return jsonify({
            "status": "unhealthy",
            "error": str(e)
        }), 500

if __name__ == "__main__":
    load_all_data()
    logger.info(f"‚úÖ M√°y ch·ªß Backend ƒë√£ s·∫µn s√†ng. http://{FLASK_HOST}:{FLASK_PORT}")
    app.run(debug=FLASK_DEBUG, host=FLASK_HOST, port=FLASK_PORT)